{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_decoding_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhengro/DL-Identification/blob/sara-mlp_decoder_2/ANN_decoding_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5Pj2AaWxY4En",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "metadata": {
        "id": "4UZA9QlgYyg0",
        "colab_type": "code",
        "outputId": "21ac7c4f-7de0-480e-e31b-66a8b16e0a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import numpy.matlib\n",
        "import math\n",
        "import random\n",
        "from numpy.random import random as rand\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y4NqB94tY_a1",
        "colab_type": "code",
        "outputId": "557da382-2531-456a-cc28-9c5e658d8d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8v_KkcSCZEWB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ]
    },
    {
      "metadata": {
        "id": "nO-dNiW5ZHot",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "N = 256                     # data sequence length\n",
        "M = 1500                    # num of users\n",
        "R = 0.5                     # compression rate\n",
        "bsc_err = 0.1               # cross over prob. \n",
        "epochs = 2**14              # number of learning epochs\n",
        "design = [16*N, 16*N]      # each list entry defines the number of nodes in a layer\n",
        "batch_size = 100            # size of batches for calculation the gradient\n",
        "optimizer = 'nadam'           \n",
        "loss ='binary_crossentropy'\n",
        "obs_per_user = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MO7kXS384HKm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import data"
      ]
    },
    {
      "metadata": {
        "id": "8TxMRQyX4I_1",
        "colab_type": "code",
        "outputId": "cbc7acbf-7521-4909-bb37-fa6d122c77bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/My Drive/Colab Notebooks/{}_data_len_{}/bsc_err_{}'.format(M, N, bsc_err)\n",
        "path_to_orig_data = base_path + '/original_data_{}.txt'.format(R)\n",
        "# path_to_observations = base_path + \"/observations_{}.txt\".format(R)\n",
        "path_to_db = base_path + \"/db_{}.txt\".format(R)\n",
        "path_to_decompressed_db = base_path + \"/decompressed_db_{}.txt\".format(R)\n",
        "\n",
        "orig_data = np.loadtxt(path_to_orig_data, delimiter=',', dtype=bool)\n",
        "# observations = np.loadtxt(path_to_observations, delimiter=',', dtype=bool)\n",
        "db = np.loadtxt(path_to_db, delimiter=',', dtype=bool)\n",
        "decompressed_db = np.loadtxt(path_to_decompressed_db, delimiter=',', dtype=bool)\n",
        "print('size is:', orig_data.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size is: (1500, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OZhIibKwZOQd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Calculate free/frozen indexes"
      ]
    },
    {
      "metadata": {
        "id": "-A17BsK_ZTWD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Input to this function can be an array of probabilities\n",
        "def get_entropy(x):\n",
        "    # Calculates entropy for a single value\n",
        "    def get_single_entropy(p):\n",
        "        if p == 1 or p == 0:\n",
        "            return 0\n",
        "        h = -p * np.log2(p) - (1-p) * np.log2(1-p)\n",
        "        return h\n",
        "    dummy_func = np.vectorize(get_single_entropy)\n",
        "    return dummy_func(x)\n",
        "  \n",
        "  \n",
        "def reverse_entropy(y):\n",
        "    xu = 0.5\n",
        "    xd = 0\n",
        "    tst = y\n",
        "    val = get_entropy(tst)\n",
        "\n",
        "    while abs(val - y) > 0.0000001:\n",
        "        if val > y:\n",
        "            xx = xd\n",
        "            xu = tst\n",
        "        else:\n",
        "            xx = xu\n",
        "            xd = tst\n",
        "        tst = tst + (y - val) * (xx - tst) / (get_entropy(xx) - val + np.finfo(float).eps)\n",
        "        val = get_entropy(tst)\n",
        "    if tst < 0.5:\n",
        "        x = tst\n",
        "    else:\n",
        "        x = 1 - tst\n",
        "\n",
        "    return x\n",
        "\n",
        "  \n",
        "def get_bec_bhattacharyya(N, e):\n",
        "    # e is erasure rate\n",
        "    # N is number of channels (length of the sequence)\n",
        "\n",
        "    n = math.log2(N)\n",
        "    Z = np.zeros(N)\n",
        "    Z[0] = e\n",
        "    temp1 = np.zeros(N)\n",
        "    for i in range(int(n)):\n",
        "        for ii in range(int(2 ** i)):\n",
        "            temp1[2 * ii] = 2 * Z[ii] - Z[ii] * Z[ii]\n",
        "            temp1[2 * ii + 1] = Z[ii] * Z[ii]\n",
        "        Z = temp1.copy()\n",
        "\n",
        "    return Z  \n",
        "  \n",
        "  \n",
        "# compression rate must be 0 < R < 1\n",
        "def get_free_indexes(N, compresseion_rate):\n",
        "\n",
        "    distortion = reverse_entropy(1 - compresseion_rate)\n",
        "    # print('this is the distortion:', distortion)\n",
        "    bits_per_user = round(N * compresseion_rate)\n",
        "    # print('bits per user:', bits_per_user)\n",
        "    bhat_param = get_bec_bhattacharyya(N, get_entropy(distortion))\n",
        "    # print('this is the bhat param:', bhat_param)\n",
        "\n",
        "    sorted_bhat_param_index = bhat_param.argsort()\n",
        "    # frozen_index = sorted_bhat_param_index[N - bits_per_user:]\n",
        "    free_index = sorted_bhat_param_index[:N - bits_per_user]\n",
        "    # print(frozen_index)\n",
        "    # print(free_index)\n",
        "    return free_index\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "utnbfvt64gWw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define NN model"
      ]
    },
    {
      "metadata": {
        "id": "oHp7J1Ds4ww5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compose_model(layers):\n",
        "    model = Sequential()\n",
        "    for layer in layers:\n",
        "        model.add(layer)\n",
        "    return model\n",
        "  \n",
        "  \n",
        "def errors(y_true, y_pred):\n",
        "    return K.sum(K.cast(K.not_equal(y_true, K.round(y_pred)), 'uint16'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LJAbSEo748tW",
        "colab_type": "code",
        "outputId": "fedc5493-bbb3-4bd7-90ef-cf99f0fa23c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "free_indexes = get_free_indexes(N, R)\n",
        "num_free_indexes = len(free_indexes)\n",
        "db_free = db[:, free_indexes]\n",
        "print(db_free.shape)\n",
        "\n",
        "# Define decoder \n",
        "decoder_layers = [Dense(design[0], activation='relu', input_shape=(N,))]\n",
        "\n",
        "for i in range(1,len(design)):\n",
        "    decoder_layers.append(Dense(design[i], activation='relu'))\n",
        "    \n",
        "decoder_layers.append(Dense(num_free_indexes, activation='sigmoid'))\n",
        "model = compose_model(decoder_layers)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[errors])\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1500, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "10vu4S5r5PCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "ifJw6efD5QJc",
        "colab_type": "code",
        "outputId": "0dbc3c37-030a-414d-cfc7-712aa8175392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "history = model.fit(orig_data, db_free, batch_size=batch_size, epochs=epochs, verbose=0, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               524416    \n",
            "=================================================================\n",
            "Total params: 18,358,400\n",
            "Trainable params: 18,358,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tJkFqRyZhV8M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generate observations"
      ]
    },
    {
      "metadata": {
        "id": "_yCjnvlXhYen",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input bits is a M*N array\n",
        "def bsc(input_bits, p_t):\n",
        "  M = input_bits.shape[0]\n",
        "  N = input_bits.shape[1]\n",
        "  output_bits = input_bits.copy()\n",
        "  flip_locs = (rand((M, N)) <= p_t)\n",
        "  output_bits[flip_locs] = 1 ^ output_bits[flip_locs]\n",
        "  return output_bits\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1IZoy3COhbIZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "observations = bsc(np.tile(orig_data, (obs_per_user, 1)), bsc_err)\n",
        "true_labels = np.tile(np.arange(M), (1, obs_per_user))\n",
        "# print(true_labels)\n",
        "# print(observations.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m5sAzRlt8V_c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ]
    },
    {
      "metadata": {
        "id": "IsZae6Ge8Z9W",
        "colab_type": "code",
        "outputId": "84e26eaa-4072-40e3-d83e-26e791985d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predicted_compressed = model.predict(observations, verbose=1, steps=None)\n",
        "predictions = np.rint(predicted_compressed)\n",
        "# print(np.sum(abs(predictions - db), axis=1))\n",
        "# not_same = np.mean(np.sum(abs(predictions - db), axis=1)) / N\n",
        "# print(np.mean(np.sum(abs(predictions - db), axis=1)))\n",
        "# print(not_same)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15000/15000 [==============================] - 0s 23us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xBIdFJTp8cjF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exhaustive search to get index"
      ]
    },
    {
      "metadata": {
        "id": "UsomA2Sl8isc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_index_mmi(y, x):\n",
        "  # y is the db (array of vectors)\n",
        "  # x is the observation (one vector)  \n",
        "  length = y.shape[0]\n",
        "  mi = np.zeros(length)\n",
        "  for i in range(length):\n",
        "    mi[i] = normalized_mutual_info_score (y[i, :], x)\n",
        "  \n",
        "  return np.argmin(mi)\n",
        "\n",
        "\n",
        "def get_err_mmi(predictions, db_free, true_labels):\n",
        "  length = predictions.shape[0]\n",
        "  pred_index = np.zeros(length)\n",
        "  for i in range(length):\n",
        "    pred_index [i] = get_index_mmi(db_free, predictions[i, :])\n",
        "    print(i)\n",
        "    \n",
        "  num_err = np.count_nonzero( pred_index - true_labels )\n",
        "  err = num_err/length\n",
        "  return num_err, err\n",
        "\n",
        "\n",
        "\n",
        "def get_index_hamming(y, x):\n",
        "    # y is the db (array of vectors)\n",
        "    # x is the observation (one vector)  \n",
        "    x_large = numpy.matlib.repmat(x, y.shape[0], 1)\n",
        "    hamming_distance = np.sum(np.logical_xor(x_large, y), axis=1)\n",
        "    index_of_min = np.argmin(hamming_distance)\n",
        "    return index_of_min\n",
        "  \n",
        "  \n",
        "def get_err_hamming(predictions, db_free, true_labels):\n",
        "  length = predictions.shape[0]\n",
        "  pred_index = np.zeros(length)\n",
        "  \n",
        "  for i in range(length):\n",
        "    pred_index [i] = get_index_hamming(db_free, predictions[i, :])\n",
        "    \n",
        "  num_err = np.count_nonzero( pred_index - true_labels )\n",
        "  err = num_err/length\n",
        "  return num_err, err"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YeJ8CCz69b7A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Calculate error"
      ]
    },
    {
      "metadata": {
        "id": "2963WP5j9fjn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_err_hamming, err_hamming = get_err_hamming(predictions, db_free, true_labels)\n",
        "# num_err_mmi, err_mmi = get_err_mmi(predictions, db_free, true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9ESGYbV29ofZ",
        "colab_type": "code",
        "outputId": "8e22c518-965e-46a7-a8dc-833a55349afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('number of error for hamming distance:', num_err_hamming)\n",
        "print ('error for hamming distance:', err_hamming)\n",
        "\n",
        "# print('number of error for mmi:', num_err_mmi)\n",
        "# print ('error for mmi:', err_mmi)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of error for hamming distance: 14373\n",
            "error for hamming distance: 0.9582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HtvvEgIK9lPT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save results"
      ]
    },
    {
      "metadata": {
        "id": "8Hp_ESYi9srr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "str = 'num_err_mmi = {}, pe_mmi = {}, num_err_hamming= {}, pe_hamming= {}, N= {}, M= {}, bsc_err= {}, R= {},\\\n",
        "  hidden_layers= {}, cost_func= {}, not_same={} \\n'.format(num_err_mmi, err_mmi, num_err_hamming, \n",
        "                                            err_hamming, N, M, bsc_err, R, design, loss, not_same)\n",
        "file_path = base_path + '/results_2.txt'\n",
        "with open(file_path, \"a\") as myfile:\n",
        "    myfile.write(str)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}