{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhengro/DL-Identification/blob/narrow-the-exhaustive-search-range/train%20a%20mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GjpXPkcdjSIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import commpy.channels\n",
        "import matlab.engine\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eng = matlab.engine.start_matlab()\n",
        "\n",
        "b = 0  # value of frozen bits\n",
        "R = 0.5  # compression rate\n",
        "D = eng.hbinv(1-R)  # corresponding distortion\n",
        "\n",
        "MM = np.array([[500]])  # number of users\n",
        "# MM = np.linspace(500, 2000, num=4)\n",
        "\n",
        "bsc_e = np.array([[0.3]])  # crossover probability of BSC\n",
        "# bsc_e = np.linspace(0.1, 0.4, num=7)\n",
        "\n",
        "N = np.array([[256]])  # data length\n",
        "# N = np.array([[64, 128, 256]])  \n",
        "\n",
        "# find error rate\n",
        "for im in range(MM.size):\n",
        "    M = MM[0, im]\n",
        "    err_mtx = np.zeros((bsc_e.size, N.size))\n",
        "    for ie in range(bsc_e.size):\n",
        "        e = bsc_e[0, ie]\n",
        "        err = np.zeros((1, N.size))\n",
        "        for i in range(N.size):\n",
        "            L = N[0, i]\n",
        "            K = int(np.round(L*R))\n",
        "\n",
        "            Z = eng.get_bec_bhattacharyya(float(L), eng.h_2(D))\n",
        "            index = np.argsort(Z).ravel()\n",
        "            index = index[::-1]  # sort Z descend using 2 steps\n",
        "            free_index = index[L-K:L]+1  # messages indices ‘+1’ is to be adapted for MATLAB\n",
        "            frozen_index = index[0:L-K]+1  # frozen indices\n",
        "            free_index = matlab.int64(free_index.tolist())  # preparation\n",
        "            frozen_index = matlab.int64(frozen_index.tolist())\n",
        "\n",
        "            data_u = np.zeros((M, L))  # original data\n",
        "            data_y = np.zeros((M, L))  # compressed data\n",
        "            data_y2 = np.zeros((M, L))  # reconstruction of compressed data\n",
        "            data_z = np.zeros((M, L))  # observation\n",
        "            h_y = np.zeros((1, M))\n",
        "            h_z = np.zeros((1, M))\n",
        "            I_xz = np.zeros((1, M))\n",
        "            w_hat = np.zeros((1, M))\n",
        "\n",
        "            for j in range(M):\n",
        "                data_u[j, :] = np.random.rand(1, L) <= 0.5\n",
        "                temp = eng.sc_SC(matlab.double(data_u[j, :].tolist()), free_index, frozen_index, D)\n",
        "                data_y[j, :] = np.asarray(temp).ravel()\n",
        "\n",
        "                temp = eng.channel_encoder(matlab.double(data_y[j, :].tolist()))\n",
        "                data_y2[j, :] = np.asarray(temp).ravel()\n",
        "\n",
        "                h_y[0, j] = eng.h_2(float(np.mean(data_y2[j, :])))\n",
        "            for j in range(M):\n",
        "                data_z[j, :] = commpy.channels.bsc(np.int_(data_u[j, :]), e)\n",
        "        # MMI identification method\n",
        "        #         temp = matlab.double(data_z[j, :].tolist())\n",
        "        #         h_z[0, j] = eng.h_2(float(np.mean(data_z[j, :])))\n",
        "        #         for k in range(M):\n",
        "        #             h_xz = eng.get_type_entropy(temp, matlab.double(data_y2[k, :].tolist()))\n",
        "        #             I_xz[0, k] = h_y[0, k] + h_z[0, j] - h_xz\n",
        "        #         w_hat[0, j] = np.argmax(I_xz)\n",
        "        #         if w_hat[0, j] != j:\n",
        "        #             err[0, i] = err[0, i] + 1\n",
        "        # err = err / M\n",
        "        # err_mtx[ie, :] = err\n",
        "\n",
        "eng.quit()\n",
        "\n",
        "# clustering\n",
        "num_clusters = 5\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(data_u)\n",
        "cluster_label = kmeans.labels_.tolist()\n",
        "centroids = kmeans.cluster_centers_\n",
        "plt.hist(cluster_label, bins=num_clusters)\n",
        "plt.title('Histogram with cluster_label')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "def dec_to_bin(x, n):\n",
        "    idx = len(x)\n",
        "    y = np.zeros((idx, n))\n",
        "    for i in range(idx):\n",
        "        temp_idx = int(x[i])\n",
        "        y[i, temp_idx] = 1\n",
        "    return y\n",
        "\n",
        "\n",
        "# construct train set and test set\n",
        "ns = [800, 200]  # ns is the number of noisy samples for each users [train, test]\n",
        "t1 = np.zeros((500, ns[0], 256))\n",
        "t2 = np.zeros((500, ns[1], 256))\n",
        "a1 = np.zeros((500, ns[0], 1))\n",
        "a2 = np.zeros((500, ns[1], 1))\n",
        "for j in range(500):\n",
        "    for i in range(ns[0]):\n",
        "        t1[j, i, :] = commpy.channels.bsc(np.int_(data_u[j, :]), e)\n",
        "        a1[j, i, :] = cluster_label[j]\n",
        "    for i in range(ns[1]):\n",
        "        t2[j, i, :] = commpy.channels.bsc(np.int_(data_u[j, :]), e)\n",
        "        a2[j, i, :] = cluster_label[j]\n",
        "train = t1.reshape((500*ns[0], 256))  \n",
        "test = t2.reshape((500*ns[1], 256))  \n",
        "train_target = a1.reshape((500*ns[0], 1)).ravel()  \n",
        "test_target = a2.reshape((500*ns[1], 1)).ravel() \n",
        "bin_train_target = dec_to_bin(train_target, num_clusters)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZuD_uVmEg8qn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# data generated as above\n",
        "train = np.loadtxt(open('train.csv', 'rb'), delimiter=',', skiprows=0)  # 400000*256\n",
        "bin_train_target = np.loadtxt(open('bin_train_target.csv', 'rb'), delimiter=',', skiprows=0)  # 400000*5\n",
        "test = np.loadtxt(open('test.csv', 'rb'), delimiter=',', skiprows=0)  # 100000*256\n",
        "test_target = np.loadtxt(open('test_target.csv', 'rb'), delimiter=',', skiprows=0)  # 100000*1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gq4r3Rq512b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3394
        },
        "outputId": "4ea2768b-b5bd-45ce-a13a-8db0c72a20aa"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# parameters\n",
        "epoch = 100\n",
        "batch_size = 3200\n",
        "layer1_dim = 120\n",
        "layer2_dim = 80\n",
        "layer3_dim = 50\n",
        "\n",
        "input_img = Input(shape=(256, ))\n",
        "encoded1 = Dense(layer1_dim, activation='relu')(input_img)\n",
        "encoded2 = Dense(layer2_dim, activation='relu')(encoded1)\n",
        "encoded3 = Dense(layer3_dim, activation='relu')(encoded2)\n",
        "out = Dense(5, activation='sigmoid')(encoded3)\n",
        "\n",
        "mlp = Model(input_img, out)\n",
        "mlp.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "mlp.fit(train, bin_train_target, epochs=epoch, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_preds = mlp.predict(test)\n",
        "predictions = np.argmax(test_preds, axis=1)\n",
        "diff = predictions - test_target\n",
        "errate = np.count_nonzero(diff)/len(predictions)\n",
        "print(\"Error rate:%s\" % errate)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "400000/400000 [==============================] - 5s 13us/step - loss: 1.4298 - acc: 0.3955\n",
            "Epoch 2/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 1.2375 - acc: 0.5005\n",
            "Epoch 3/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 1.1837 - acc: 0.5266\n",
            "Epoch 4/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 1.1254 - acc: 0.5571\n",
            "Epoch 5/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 1.0536 - acc: 0.5916\n",
            "Epoch 6/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.9895 - acc: 0.6203\n",
            "Epoch 7/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.9301 - acc: 0.6463\n",
            "Epoch 8/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.8801 - acc: 0.6676\n",
            "Epoch 9/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.8274 - acc: 0.6894\n",
            "Epoch 10/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.7960 - acc: 0.7033\n",
            "Epoch 11/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.7583 - acc: 0.7182\n",
            "Epoch 12/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.7273 - acc: 0.7307\n",
            "Epoch 13/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.7003 - acc: 0.7412\n",
            "Epoch 14/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.6763 - acc: 0.7513\n",
            "Epoch 15/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.6584 - acc: 0.7590\n",
            "Epoch 16/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.6423 - acc: 0.7644\n",
            "Epoch 17/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.6222 - acc: 0.7728\n",
            "Epoch 18/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.6078 - acc: 0.7782\n",
            "Epoch 19/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5932 - acc: 0.7839\n",
            "Epoch 20/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5803 - acc: 0.7891\n",
            "Epoch 21/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5717 - acc: 0.7922\n",
            "Epoch 22/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5579 - acc: 0.7978\n",
            "Epoch 23/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5518 - acc: 0.7999\n",
            "Epoch 24/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5426 - acc: 0.8033\n",
            "Epoch 25/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5309 - acc: 0.8077\n",
            "Epoch 26/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5287 - acc: 0.8088\n",
            "Epoch 27/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5182 - acc: 0.8131\n",
            "Epoch 28/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5111 - acc: 0.8156\n",
            "Epoch 29/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5051 - acc: 0.8181\n",
            "Epoch 30/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.5007 - acc: 0.8200\n",
            "Epoch 31/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4945 - acc: 0.8217\n",
            "Epoch 32/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4873 - acc: 0.8244\n",
            "Epoch 33/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4841 - acc: 0.8257\n",
            "Epoch 34/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4801 - acc: 0.8271\n",
            "Epoch 35/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4758 - acc: 0.8294\n",
            "Epoch 36/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4739 - acc: 0.8296\n",
            "Epoch 37/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4686 - acc: 0.8317\n",
            "Epoch 38/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4650 - acc: 0.8335\n",
            "Epoch 39/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4611 - acc: 0.8352\n",
            "Epoch 40/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4590 - acc: 0.8353\n",
            "Epoch 41/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4577 - acc: 0.8364\n",
            "Epoch 42/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4528 - acc: 0.8381\n",
            "Epoch 43/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4475 - acc: 0.8401\n",
            "Epoch 44/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4450 - acc: 0.8409\n",
            "Epoch 45/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4438 - acc: 0.8412\n",
            "Epoch 46/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4413 - acc: 0.8424\n",
            "Epoch 47/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4391 - acc: 0.8431\n",
            "Epoch 48/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4337 - acc: 0.8453\n",
            "Epoch 49/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4342 - acc: 0.8453\n",
            "Epoch 50/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4342 - acc: 0.8445\n",
            "Epoch 51/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4307 - acc: 0.8457\n",
            "Epoch 52/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4266 - acc: 0.8480\n",
            "Epoch 53/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4257 - acc: 0.8478\n",
            "Epoch 54/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4243 - acc: 0.8485\n",
            "Epoch 55/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4237 - acc: 0.8484\n",
            "Epoch 56/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4215 - acc: 0.8495\n",
            "Epoch 57/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4189 - acc: 0.8509\n",
            "Epoch 58/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4168 - acc: 0.8514\n",
            "Epoch 59/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4152 - acc: 0.8518\n",
            "Epoch 60/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4146 - acc: 0.8519\n",
            "Epoch 61/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4111 - acc: 0.8534\n",
            "Epoch 62/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4118 - acc: 0.8532\n",
            "Epoch 63/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4096 - acc: 0.8538\n",
            "Epoch 64/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4086 - acc: 0.8542\n",
            "Epoch 65/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4065 - acc: 0.8551\n",
            "Epoch 66/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4046 - acc: 0.8558\n",
            "Epoch 67/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4046 - acc: 0.8559\n",
            "Epoch 68/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4033 - acc: 0.8554\n",
            "Epoch 69/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4001 - acc: 0.8574\n",
            "Epoch 70/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3987 - acc: 0.8578\n",
            "Epoch 71/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3993 - acc: 0.8576\n",
            "Epoch 72/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3968 - acc: 0.8590\n",
            "Epoch 73/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3945 - acc: 0.8592\n",
            "Epoch 74/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3944 - acc: 0.8596\n",
            "Epoch 75/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3937 - acc: 0.8600\n",
            "Epoch 76/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3939 - acc: 0.8598\n",
            "Epoch 77/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3913 - acc: 0.8602\n",
            "Epoch 78/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3905 - acc: 0.8613\n",
            "Epoch 79/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3885 - acc: 0.8619\n",
            "Epoch 80/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3887 - acc: 0.8618\n",
            "Epoch 81/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3871 - acc: 0.8623\n",
            "Epoch 82/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3858 - acc: 0.8627\n",
            "Epoch 83/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3863 - acc: 0.8628\n",
            "Epoch 84/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3841 - acc: 0.8636\n",
            "Epoch 85/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3838 - acc: 0.8636\n",
            "Epoch 86/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3821 - acc: 0.8640\n",
            "Epoch 87/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3813 - acc: 0.8649\n",
            "Epoch 88/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3821 - acc: 0.8642\n",
            "Epoch 89/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3801 - acc: 0.8650\n",
            "Epoch 90/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3787 - acc: 0.8653\n",
            "Epoch 91/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3780 - acc: 0.8657\n",
            "Epoch 92/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3773 - acc: 0.8660\n",
            "Epoch 93/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3765 - acc: 0.8668\n",
            "Epoch 94/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3758 - acc: 0.8666\n",
            "Epoch 95/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3754 - acc: 0.8671\n",
            "Epoch 96/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3748 - acc: 0.8667\n",
            "Epoch 97/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3739 - acc: 0.8670\n",
            "Epoch 98/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3735 - acc: 0.8673\n",
            "Epoch 99/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3723 - acc: 0.8678\n",
            "Epoch 100/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.3725 - acc: 0.8680\n",
            "Error rate:0.19064\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}