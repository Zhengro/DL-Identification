{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhengro/DL-Identification/blob/narrow-the-exhaustive-search-range/train%20a%20mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GjpXPkcdjSIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import commpy.channels\n",
        "import matlab.engine\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eng = matlab.engine.start_matlab()\n",
        "\n",
        "b = 0  # value of frozen bits\n",
        "R = 0.5  # compression rate\n",
        "D = eng.hbinv(1-R)  # corresponding distortion\n",
        "\n",
        "MM = 500  # number of users\n",
        "MM = np.array([[MM]])\n",
        "# MM = np.linspace(500, 2000, num=4)\n",
        "\n",
        "bsc_e = 0.3  # crossover probability of BSC\n",
        "bsc_e = np.array([[bsc_e]])\n",
        "# bsc_e = np.linspace(0.1, 0.4, num=7)\n",
        "\n",
        "# N = np.array([[64, 128, 256]])  # data length\n",
        "N = 256\n",
        "N = np.array([[N]])\n",
        "\n",
        "# find error rate\n",
        "for im in range(MM.size):\n",
        "    M = MM[0, im]\n",
        "    err_mtx = np.zeros((bsc_e.size, N.size))\n",
        "    for ie in range(bsc_e.size):\n",
        "        e = bsc_e[0, ie]\n",
        "        err = np.zeros((1, N.size))\n",
        "        for i in range(N.size):\n",
        "            L = N[0, i]\n",
        "            K = int(np.round(L*R))\n",
        "\n",
        "            Z = eng.get_bec_bhattacharyya(float(L), eng.h_2(D))\n",
        "            index = np.argsort(Z).ravel()\n",
        "            index = index[::-1]  # sort Z descend using 2 steps\n",
        "            free_index = index[L-K:L]+1  # messages indices ‘+1’ is to be adapted for MATLAB\n",
        "            frozen_index = index[0:L-K]+1  # frozen indices\n",
        "            free_index = matlab.int64(free_index.tolist())  # preparation\n",
        "            frozen_index = matlab.int64(frozen_index.tolist())\n",
        "\n",
        "            data_u = np.zeros((M, L))  # original data\n",
        "            data_y = np.zeros((M, L))  # compressed data\n",
        "            data_y2 = np.zeros((M, L))  # reconstruction of compressed data\n",
        "            data_z = np.zeros((M, L))  # observation\n",
        "            h_y = np.zeros((1, M))\n",
        "            h_z = np.zeros((1, M))\n",
        "            I_xz = np.zeros((1, M))\n",
        "            w_hat = np.zeros((1, M))\n",
        "\n",
        "            for j in range(M):\n",
        "                data_u[j, :] = np.random.rand(1, L) <= 0.5\n",
        "                temp = eng.sc_SC(matlab.double(data_u[j, :].tolist()), free_index, frozen_index, D)\n",
        "                data_y[j, :] = np.asarray(temp).ravel()\n",
        "\n",
        "                temp = eng.channel_encoder(matlab.double(data_y[j, :].tolist()))\n",
        "                data_y2[j, :] = np.asarray(temp).ravel()\n",
        "\n",
        "                h_y[0, j] = eng.h_2(float(np.mean(data_y2[j, :])))\n",
        "            for j in range(M):\n",
        "                data_z[j, :] = commpy.channels.bsc(np.int_(data_u[j, :]), e)\n",
        "        # MMI identification method\n",
        "        #         temp = matlab.double(data_z[j, :].tolist())\n",
        "        #         h_z[0, j] = eng.h_2(float(np.mean(data_z[j, :])))\n",
        "        #         for k in range(M):\n",
        "        #             h_xz = eng.get_type_entropy(temp, matlab.double(data_y2[k, :].tolist()))\n",
        "        #             I_xz[0, k] = h_y[0, k] + h_z[0, j] - h_xz\n",
        "        #         w_hat[0, j] = np.argmax(I_xz)\n",
        "        #         if w_hat[0, j] != j:\n",
        "        #             err[0, i] = err[0, i] + 1\n",
        "        # err = err / M\n",
        "        # err_mtx[ie, :] = err\n",
        "\n",
        "eng.quit()\n",
        "\n",
        "# clustering\n",
        "num_clusters = 5\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(data_u)\n",
        "cluster_label = kmeans.labels_.tolist()\n",
        "centroids = kmeans.cluster_centers_\n",
        "plt.hist(cluster_label, bins=num_clusters)\n",
        "plt.title('Histogram with cluster_label')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "def dec_to_bin(x, n):\n",
        "    idx = len(x)\n",
        "    y = np.zeros((idx, n))\n",
        "    for i in range(idx):\n",
        "        temp_idx = int(x[i])\n",
        "        y[i, temp_idx] = 1\n",
        "    return y\n",
        "\n",
        "\n",
        "# construct train set and test set\n",
        "ns = [800, 200]  # ns is the number of noisy samples for each users [train, test]\n",
        "t1 = np.zeros((500, ns[0], 256))\n",
        "t2 = np.zeros((500, ns[1], 256))\n",
        "a1 = np.zeros((500, ns[0], 1))\n",
        "a2 = np.zeros((500, ns[1], 1))\n",
        "for j in range(500):\n",
        "    for i in range(ns[0]):\n",
        "        t1[j, i, :] = commpy.channels.bsc(np.int_(data_u[j, :]), e)\n",
        "        a1[j, i, :] = cluster_label[j]\n",
        "    for i in range(ns[1]):\n",
        "        t2[j, i, :] = commpy.channels.bsc(np.int_(data_u[j, :]), e)\n",
        "        a2[j, i, :] = cluster_label[j]\n",
        "train = t1.reshape((500*ns[0], 256))  \n",
        "test = t2.reshape((500*ns[1], 256))  \n",
        "train_target = a1.reshape((500*ns[0], 1)).ravel()  \n",
        "test_target = a2.reshape((500*ns[1], 1)).ravel() \n",
        "bin_train_target = dec_to_bin(train_target, num_clusters)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZuD_uVmEg8qn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# data generated as above\n",
        "train = np.loadtxt(open('train.csv', 'rb'), delimiter=',', skiprows=0)  # 400000*256\n",
        "bin_train_target = np.loadtxt(open('bin_train_target.csv', 'rb'), delimiter=',', skiprows=0)  # 400000*5\n",
        "test = np.loadtxt(open('test.csv', 'rb'), delimiter=',', skiprows=0)  # 100000*256\n",
        "test_target = np.loadtxt(open('test_target.csv', 'rb'), delimiter=',', skiprows=0)  # 100000*1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gq4r3Rq512b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3394
        },
        "outputId": "73b566da-3238-4d2a-b56c-26bc07715197"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "# parameters\n",
        "epoch = 100\n",
        "batch_size = 6400\n",
        "layer1_dim = 120\n",
        "layer2_dim = 80\n",
        "layer3_dim = 50\n",
        "\n",
        "input_img = Input(shape=(256, ))\n",
        "encoded1 = Dense(layer1_dim, activation='relu')(input_img)\n",
        "encoded2 = Dense(layer2_dim, activation='relu')(encoded1)\n",
        "encoded3 = Dense(layer3_dim, activation='relu')(encoded2)\n",
        "out = Dense(5, activation='sigmoid')(encoded3)\n",
        "\n",
        "mlp = Model(input_img, out)\n",
        "mlp.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "mlp.fit(train, bin_train_target, epochs=epoch, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_preds = mlp.predict(test)\n",
        "predictions = np.argmax(test_preds, axis=1)\n",
        "diff = predictions - test_target\n",
        "errate = np.count_nonzero(diff)/len(predictions)\n",
        "print(\"Error rate:%s\" % errate)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "400000/400000 [==============================] - 5s 12us/step - loss: 1.4912 - acc: 0.3484\n",
            "Epoch 2/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 1.3233 - acc: 0.4636\n",
            "Epoch 3/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 1.2544 - acc: 0.4920\n",
            "Epoch 4/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 1.2140 - acc: 0.5115\n",
            "Epoch 5/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 1.1974 - acc: 0.5195\n",
            "Epoch 6/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 1.1709 - acc: 0.5332\n",
            "Epoch 7/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 1.1432 - acc: 0.5470\n",
            "Epoch 8/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 1.1067 - acc: 0.5648\n",
            "Epoch 9/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 1.0814 - acc: 0.5777\n",
            "Epoch 10/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 1.0505 - acc: 0.5928\n",
            "Epoch 11/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 1.0182 - acc: 0.6063\n",
            "Epoch 12/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.9849 - acc: 0.6225\n",
            "Epoch 13/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.9578 - acc: 0.6336\n",
            "Epoch 14/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.9332 - acc: 0.6444\n",
            "Epoch 15/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.9051 - acc: 0.6571\n",
            "Epoch 16/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.8777 - acc: 0.6701\n",
            "Epoch 17/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.8588 - acc: 0.6769\n",
            "Epoch 18/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.8340 - acc: 0.6868\n",
            "Epoch 19/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.8190 - acc: 0.6941\n",
            "Epoch 20/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.7978 - acc: 0.7025\n",
            "Epoch 21/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.7810 - acc: 0.7098\n",
            "Epoch 22/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.7662 - acc: 0.7160\n",
            "Epoch 23/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.7503 - acc: 0.7218\n",
            "Epoch 24/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.7337 - acc: 0.7286\n",
            "Epoch 25/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.7214 - acc: 0.7335\n",
            "Epoch 26/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.7088 - acc: 0.7383\n",
            "Epoch 27/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.6995 - acc: 0.7427\n",
            "Epoch 28/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.6877 - acc: 0.7471\n",
            "Epoch 29/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.6780 - acc: 0.7501\n",
            "Epoch 30/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.6678 - acc: 0.7540\n",
            "Epoch 31/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.6546 - acc: 0.7600\n",
            "Epoch 32/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.6463 - acc: 0.7637\n",
            "Epoch 33/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.6416 - acc: 0.7650\n",
            "Epoch 34/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.6301 - acc: 0.7702\n",
            "Epoch 35/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.6248 - acc: 0.7712\n",
            "Epoch 36/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.6143 - acc: 0.7759\n",
            "Epoch 37/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.6065 - acc: 0.7788\n",
            "Epoch 38/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.6060 - acc: 0.7792\n",
            "Epoch 39/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5960 - acc: 0.7827\n",
            "Epoch 40/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5913 - acc: 0.7842\n",
            "Epoch 41/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5822 - acc: 0.7881\n",
            "Epoch 42/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5745 - acc: 0.7916\n",
            "Epoch 43/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5727 - acc: 0.7919\n",
            "Epoch 44/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5661 - acc: 0.7948\n",
            "Epoch 45/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5637 - acc: 0.7951\n",
            "Epoch 46/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5549 - acc: 0.7985\n",
            "Epoch 47/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5555 - acc: 0.7989\n",
            "Epoch 48/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5424 - acc: 0.8037\n",
            "Epoch 49/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5496 - acc: 0.8005\n",
            "Epoch 50/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5369 - acc: 0.8055\n",
            "Epoch 51/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5329 - acc: 0.8073\n",
            "Epoch 52/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5280 - acc: 0.8092\n",
            "Epoch 53/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5261 - acc: 0.8101\n",
            "Epoch 54/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5269 - acc: 0.8097\n",
            "Epoch 55/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5176 - acc: 0.8128\n",
            "Epoch 56/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5112 - acc: 0.8151\n",
            "Epoch 57/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5146 - acc: 0.8141\n",
            "Epoch 58/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5128 - acc: 0.8145\n",
            "Epoch 59/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5099 - acc: 0.8161\n",
            "Epoch 60/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.5035 - acc: 0.8186\n",
            "Epoch 61/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4973 - acc: 0.8210\n",
            "Epoch 62/100\n",
            "400000/400000 [==============================] - 3s 9us/step - loss: 0.4952 - acc: 0.8211\n",
            "Epoch 63/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4947 - acc: 0.8216\n",
            "Epoch 64/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4903 - acc: 0.8231\n",
            "Epoch 65/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4896 - acc: 0.8235\n",
            "Epoch 66/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4912 - acc: 0.8228\n",
            "Epoch 67/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4831 - acc: 0.8259\n",
            "Epoch 68/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4795 - acc: 0.8279\n",
            "Epoch 69/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4756 - acc: 0.8288\n",
            "Epoch 70/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4805 - acc: 0.8270\n",
            "Epoch 71/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4724 - acc: 0.8304\n",
            "Epoch 72/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4706 - acc: 0.8306\n",
            "Epoch 73/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4670 - acc: 0.8327\n",
            "Epoch 74/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4692 - acc: 0.8313\n",
            "Epoch 75/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4596 - acc: 0.8350\n",
            "Epoch 76/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4666 - acc: 0.8324\n",
            "Epoch 77/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4645 - acc: 0.8329\n",
            "Epoch 78/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4565 - acc: 0.8360\n",
            "Epoch 79/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4569 - acc: 0.8359\n",
            "Epoch 80/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4561 - acc: 0.8365\n",
            "Epoch 81/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4537 - acc: 0.8374\n",
            "Epoch 82/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4530 - acc: 0.8368\n",
            "Epoch 83/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4467 - acc: 0.8398\n",
            "Epoch 84/100\n",
            "400000/400000 [==============================] - 4s 11us/step - loss: 0.4507 - acc: 0.8382\n",
            "Epoch 85/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4421 - acc: 0.8415\n",
            "Epoch 86/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4473 - acc: 0.8397\n",
            "Epoch 87/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4450 - acc: 0.8399\n",
            "Epoch 88/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4433 - acc: 0.8410\n",
            "Epoch 89/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4378 - acc: 0.8430\n",
            "Epoch 90/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4403 - acc: 0.8421\n",
            "Epoch 91/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4369 - acc: 0.8439\n",
            "Epoch 92/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4387 - acc: 0.8428\n",
            "Epoch 93/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4332 - acc: 0.8447\n",
            "Epoch 94/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4309 - acc: 0.8457\n",
            "Epoch 95/100\n",
            "400000/400000 [==============================] - 4s 9us/step - loss: 0.4323 - acc: 0.8452\n",
            "Epoch 96/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4270 - acc: 0.8469\n",
            "Epoch 97/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4325 - acc: 0.8446\n",
            "Epoch 98/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4264 - acc: 0.8470\n",
            "Epoch 99/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4259 - acc: 0.8475\n",
            "Epoch 100/100\n",
            "400000/400000 [==============================] - 4s 10us/step - loss: 0.4265 - acc: 0.8470\n",
            "Error rate:0.20318\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}