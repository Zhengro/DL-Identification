{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Map_noisyObs_to_indexes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhengro/DL-Identification/blob/jaume/Map_noisyObs_to_indexes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bGbpez8STyqr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "__author__ = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R391B8_NbeYO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import all necessary libraries and establish connection with Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "epcN9Bbvb2fG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load main libraries for the project\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8fUeRaMX55rK",
        "colab_type": "code",
        "outputId": "d42a1688-b704-42d9-e2c6-fd124264f6d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fx_wbnuH2gsL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bsc(bit_sequence, bsc_e):\n",
        "    \"\"\"\n",
        "    Binary Symmetric Channel.\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_bits : 1D ndarray containing {0, 1}\n",
        "        Input arrary of bits to the channel.\n",
        "    p_t : float in [0, 1]\n",
        "        Transition/Error probability of the channel.\n",
        "    Returns\n",
        "    -------\n",
        "    output_bits : 1D ndarray containing {0, 1}\n",
        "        Output bits from the channel.\n",
        "    \"\"\"\n",
        "    \n",
        "    random_prob = np.random.uniform(0,1,bit_sequence.shape)\n",
        "    flipped_bits = np.where(random_prob < bsc_e, 1, 0)\n",
        "    output_bits = np.subtract(bit_sequence,flipped_bits)\n",
        "    return output_bits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ECJcS7hk9cS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77a6717c-2ea1-4c3c-f3c3-983b96b7d16b"
      },
      "cell_type": "code",
      "source": [
        "# Test bsc function\n",
        "bsc_e = 0.3\n",
        "input_bits = np.zeros((100,1))\n",
        "output_bits = bsc(input_bits,bsc_e)\n",
        "print(np.count_nonzero(output_bits)/output_bits.shape[0])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yvoM3Y3VWabw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# All the data needed for this notebook is stored in MAIN_PATH\n",
        "MAIN_PATH = \"/content/drive/My Drive/Colab Notebooks/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VfH8blytbTqV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Read, normalize, and sort all user's data"
      ]
    },
    {
      "metadata": {
        "id": "if39yBbY6Dj1",
        "colab_type": "code",
        "outputId": "83e9137a-dc72-4dbf-e1d9-7e33ae77b1b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Main parameters of the fingerprints\n",
        "DATA_FILENAME = MAIN_PATH + 'data/userData_500_256.npy'\n",
        "\n",
        "# Read data from all the fingerprints\n",
        "userData = np.load(DATA_FILENAME)\n",
        "\n",
        "# Create main parameters\n",
        "NUM_USERS, NUM_FEATURES = userData.shape\n",
        "\n",
        "print(NUM_USERS)\n",
        "print(NUM_FEATURES)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sH_SjKUoWPQF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5ea118c6-fd2e-4075-81d1-0e82fe89da4d"
      },
      "cell_type": "code",
      "source": [
        "# Construct train set and test set\n",
        "NUM_SAMPLES = 400 # Number of noisy samples for each user\n",
        "X = np.zeros((NUM_USERS*NUM_SAMPLES,NUM_FEATURES))\n",
        "Y = np.zeros((NUM_USERS*NUM_SAMPLES, 1))\n",
        "\n",
        "for k in range(NUM_USERS):\n",
        "    for n in range(NUM_SAMPLES):\n",
        "        X[n + k*NUM_SAMPLES, :] = bsc(np.int_(userData[k, :]), bsc_e)\n",
        "        Y[n + k*NUM_SAMPLES] = k\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(X, Y, test_size=0.2, shuffle=True)\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160000, 256)\n",
            "(40000, 256)\n",
            "(160000, 1)\n",
            "(40000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KBv0KP1qE1iG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "6c5bdf8b-73c1-4c23-a036-127e1c679941"
      },
      "cell_type": "code",
      "source": [
        "# Build MLP model and train the NN\n",
        "clf = MLPClassifier(hidden_layer_sizes=(128, 64, 32), activation='relu',\n",
        "                    solver='adam', verbose=True, alpha=0.001) \n",
        "clf.fit(train_data,train_labels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.16368329\n",
            "Iteration 2, loss = 0.05251809\n",
            "Iteration 3, loss = 0.02160316\n",
            "Iteration 4, loss = 0.01253752\n",
            "Iteration 5, loss = 0.01128139\n",
            "Iteration 6, loss = 0.01061111\n",
            "Iteration 7, loss = 0.01079058\n",
            "Iteration 8, loss = 0.01051347\n",
            "Iteration 9, loss = 0.00869536\n",
            "Iteration 10, loss = 0.01010410\n",
            "Iteration 11, loss = 0.00889629\n",
            "Iteration 12, loss = 0.00630328\n",
            "Iteration 13, loss = 0.01000601\n",
            "Iteration 14, loss = 0.00787832\n",
            "Iteration 15, loss = 0.00561154\n",
            "Iteration 16, loss = 0.00936315\n",
            "Iteration 17, loss = 0.00812498\n",
            "Iteration 18, loss = 0.00704060\n",
            "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(128, 64, 32), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
              "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
              "       verbose=True, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "zR--nciAFk8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1eabc18-7cfc-4d29-cc56-10f68c75717e"
      },
      "cell_type": "code",
      "source": [
        "# Test MLP algorithm\n",
        "estimated_labels = clf.predict(test_data).reshape(test_labels.shape)\n",
        "error_rate = np.count_nonzero( estimated_labels - test_labels ) / len(estimated_labels)\n",
        "print(\"Error rate = %.4f\" % error_rate)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error rate = 0.0037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uxpHz-L7JYyu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}