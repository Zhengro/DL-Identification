{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhengro/DL-Identification/blob/NNE_Sara/NNE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Kl_VeoqBLBCX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ]
    },
    {
      "metadata": {
        "id": "O3rCJT9EK7nx",
        "colab_type": "code",
        "outputId": "9875652e-dc24-4b25-b4d8-3a1ca213c5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import numpy.matlib\n",
        "import math\n",
        "import random\n",
        "from numpy.random import random as rand\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "KCNVE8UcLPF4",
        "colab_type": "code",
        "outputId": "71dfb1d9-7eb2-4dc7-e8ff-5d0210a911ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F0OZ0CkaLMIi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ]
    },
    {
      "metadata": {
        "id": "v4NCPj7zLUg5",
        "colab_type": "code",
        "outputId": "a7ebffd3-f05b-4f03-bc0e-1ae2e171de7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# data sequence length\n",
        "N = 64          \n",
        "\n",
        "# num of users\n",
        "M = 1500      \n",
        "\n",
        "# compression rate\n",
        "R = 0.5   \n",
        "\n",
        "# crossover prob.\n",
        "bsc_err = 0.1           \n",
        "\n",
        "# number of learning epochs\n",
        "epochs = 300\n",
        "\n",
        "# nodes in hidden layers\n",
        "design = [1024, 1024]     \n",
        "\n",
        "# size of batches for calculation the gradient\n",
        "batch_size = 100           \n",
        "\n",
        "# optimizer \n",
        "optimizer = 'nadam'   \n",
        "\n",
        "# loss function \n",
        "loss ='binary_crossentropy'\n",
        "\n",
        "# num of observations per user (for calculating error prob.)\n",
        "obs_per_user = 100\n",
        "\n",
        "# dropout value\n",
        "dropout = 0.15\n",
        "\n",
        "# name of the file to save the results to \n",
        "filename = ''\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs: [200 250 300 350]\n",
            "dropouts: [0.05 0.1  0.15 0.2 ]\n",
            "N: [128]\n",
            "hidden layers: [[1024 1024]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sFfr-ojmLUOg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import data"
      ]
    },
    {
      "metadata": {
        "id": "Ul8TFopxLbc2",
        "colab_type": "code",
        "outputId": "37e7283f-fe16-4f2a-c532-0f57ff9a9a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/My Drive/Colab Notebooks/{}_data_len_{}/bsc_err_{}'.format(M, N, bsc_err)\n",
        "path_to_orig_data = base_path + '/original_data_{}.txt'.format(R)\n",
        "path_to_db = base_path + \"/db_{}.txt\".format(R)\n",
        "\n",
        "orig_data = np.loadtxt(path_to_orig_data, delimiter=',', dtype=bool)\n",
        "db = np.loadtxt(path_to_db, delimiter=',', dtype=bool)\n",
        "print('size is:', orig_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size is: (1000, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vb6YvKjdLd1j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Calculate free/frozen indexes"
      ]
    },
    {
      "metadata": {
        "id": "EYZdP_V7LikR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Input to this function can be an array of probabilities\n",
        "def get_entropy(x):\n",
        "    # Calculates entropy for a single value\n",
        "    def get_single_entropy(p):\n",
        "        if p == 1 or p == 0:\n",
        "            return 0\n",
        "        h = -p * np.log2(p) - (1-p) * np.log2(1-p)\n",
        "        return h\n",
        "    dummy_func = np.vectorize(get_single_entropy)\n",
        "    return dummy_func(x)\n",
        "  \n",
        "  \n",
        "def reverse_entropy(y):\n",
        "    xu = 0.5\n",
        "    xd = 0\n",
        "    tst = y\n",
        "    val = get_entropy(tst)\n",
        "\n",
        "    while abs(val - y) > 0.0000001:\n",
        "        if val > y:\n",
        "            xx = xd\n",
        "            xu = tst\n",
        "        else:\n",
        "            xx = xu\n",
        "            xd = tst\n",
        "        tst = tst + (y - val) * (xx - tst) / (get_entropy(xx) - val + np.finfo(float).eps)\n",
        "        val = get_entropy(tst)\n",
        "    if tst < 0.5:\n",
        "        x = tst\n",
        "    else:\n",
        "        x = 1 - tst\n",
        "\n",
        "    return x\n",
        "\n",
        "  \n",
        "def get_bec_bhattacharyya(N, e):\n",
        "    # e is erasure rate\n",
        "    # N is number of channels (length of the sequence)\n",
        "\n",
        "    n = math.log2(N)\n",
        "    Z = np.zeros(N)\n",
        "    Z[0] = e\n",
        "    temp1 = np.zeros(N)\n",
        "    for i in range(int(n)):\n",
        "        for ii in range(int(2 ** i)):\n",
        "            temp1[2 * ii] = 2 * Z[ii] - Z[ii] * Z[ii]\n",
        "            temp1[2 * ii + 1] = Z[ii] * Z[ii]\n",
        "        Z = temp1.copy()\n",
        "\n",
        "    return Z  \n",
        "  \n",
        "  \n",
        "# compression rate must be 0 < R < 1\n",
        "def get_free_indexes(N, compresseion_rate):\n",
        "\n",
        "    distortion = reverse_entropy(1 - compresseion_rate)\n",
        "    # print('this is the distortion:', distortion)\n",
        "    bits_per_user = round(N * compresseion_rate)\n",
        "    # print('bits per user:', bits_per_user)\n",
        "    bhat_param = get_bec_bhattacharyya(N, get_entropy(distortion))\n",
        "    # print('this is the bhat param:', bhat_param)\n",
        "\n",
        "    sorted_bhat_param_index = bhat_param.argsort()\n",
        "    # frozen_index = sorted_bhat_param_index[N - bits_per_user:]\n",
        "    free_index = sorted_bhat_param_index[:N - bits_per_user]\n",
        "    # print(frozen_index)\n",
        "    # print(free_index)\n",
        "    return free_index\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKORfkanLtHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Define NN model"
      ]
    },
    {
      "metadata": {
        "id": "P-HWbde6LxZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compose_model(layers):\n",
        "    model = Sequential()\n",
        "    for layer in layers:\n",
        "        model.add(layer)\n",
        "    return model\n",
        "  \n",
        "  \n",
        "def errors(y_true, y_pred):\n",
        "    return K.sum(K.cast(K.not_equal(y_true, K.round(y_pred)), 'uint16'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FgrIeAtxLzvW",
        "colab_type": "code",
        "outputId": "fa24d019-1bc3-48d3-a8a3-b164943f49b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "free_indexes = get_free_indexes(N, R)\n",
        "num_free_indexes = len(free_indexes)\n",
        "db_free = db[:, free_indexes]\n",
        "print(db_free.shape)\n",
        "\n",
        "# Define decoder \n",
        "decoder_layers = [Dropout(dropout, input_shape=(N,))]\n",
        "decoder_layers.append(Dense(design[0], activation='relu'))\n",
        "\n",
        "decoder_layers.append(Dropout(dropout))\n",
        "\n",
        "for i in range(1,len(design)):\n",
        "  decoder_layers.append(Dense(design[i], activation='relu'))\n",
        "  decoder_layers.append(Dropout(dropout))\n",
        "    \n",
        "decoder_layers.append(Dense(num_free_indexes, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model = compose_model(decoder_layers)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[errors])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xCHOseJRL2Ou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "dK_m3aILL4fx",
        "colab_type": "code",
        "outputId": "27690798-946a-4d29-bf4f-9e97b23399a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "history = model.fit(orig_data, db_free, batch_size=batch_size, epochs=epochs, verbose=0, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout_16 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1024)              66560     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 32)                32800     \n",
            "=================================================================\n",
            "Total params: 1,148,960\n",
            "Trainable params: 1,148,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0JW7OUGXL9VU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generate observations"
      ]
    },
    {
      "metadata": {
        "id": "mUW7EkWoMBSO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input bits is a M*N array\n",
        "def bsc(input_bits, p_t):\n",
        "  M = input_bits.shape[0]\n",
        "  N = input_bits.shape[1]\n",
        "  output_bits = input_bits.copy()\n",
        "  flip_locs = (rand((M, N)) <= p_t)\n",
        "  output_bits[flip_locs] = 1 ^ output_bits[flip_locs]\n",
        "  return output_bits\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9MRo_EqMDsA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "observations = bsc(np.tile(orig_data, (obs_per_user, 1)), bsc_err)\n",
        "true_labels = np.tile(np.arange(M), (1, obs_per_user))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DRmn5Uh8MH8w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ]
    },
    {
      "metadata": {
        "id": "foJBtg9HMLbs",
        "colab_type": "code",
        "outputId": "93f79508-5292-44f2-c7dd-d0feff81b2af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "predicted_compressed = model.predict(observations, verbose=1, steps=None)\n",
        "predictions = np.rint(predicted_compressed)\n",
        "scaled_db_free = np.tile(db_free, (obs_per_user, 1))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000/100000 [==============================] - 6s 57us/step\n",
            "[2. 0. 0. ... 0. 0. 0.]\n",
            "0.57407\n",
            "0.00896984338760376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LfkSxLm6MQaM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exhaustive search to get index"
      ]
    },
    {
      "metadata": {
        "id": "mtfZm6piMV7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_index_mmi(y, x):\n",
        "  # y is the db (array of vectors)\n",
        "  # x is the observation (one vector)  \n",
        "  length = y.shape[0]\n",
        "  mi = np.zeros(length)\n",
        "  for i in range(length):\n",
        "    mi[i] = normalized_mutual_info_score (y[i, :], x)\n",
        "  \n",
        "  return np.argmin(mi)\n",
        "\n",
        "\n",
        "def get_err_mmi(predictions, db_free, true_labels):\n",
        "  length = predictions.shape[0]\n",
        "  pred_index = np.zeros(length)\n",
        "  for i in range(length):\n",
        "    pred_index [i] = get_index_mmi(db_free, predictions[i, :])\n",
        "    print(i)\n",
        "    \n",
        "  num_err = np.count_nonzero( pred_index - true_labels )\n",
        "  err = num_err/length\n",
        "  return num_err, err\n",
        "\n",
        "\n",
        "\n",
        "def get_index_hamming(y, x):\n",
        "    # y is the db (array of vectors)\n",
        "    # x is the observation (one vector)  \n",
        "    x_large = numpy.matlib.repmat(x, y.shape[0], 1)\n",
        "    hamming_distance = np.sum(np.logical_xor(x_large, y), axis=1)\n",
        "    index_of_min = np.argmin(hamming_distance)\n",
        "    return index_of_min\n",
        "  \n",
        "  \n",
        "def get_err_hamming(predictions, db_free, true_labels):\n",
        "  length = predictions.shape[0]\n",
        "  pred_index = np.zeros(length)\n",
        "  \n",
        "  for i in range(length):\n",
        "    pred_index [i] = get_index_hamming(db_free, predictions[i, :])\n",
        "    \n",
        "  num_err = np.count_nonzero( pred_index - true_labels )\n",
        "  err = num_err/length\n",
        "  return num_err, err"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_OjFEQ_MZZk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Calculate error"
      ]
    },
    {
      "metadata": {
        "id": "st4LuVYeMejd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_err_hamming, err_hamming = get_err_hamming(predictions, db_free, true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tlIkDjDZMhA6",
        "colab_type": "code",
        "outputId": "3cd84352-1136-4fa8-a26d-004944d5108f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('number of error for hamming distance:', num_err_hamming)\n",
        "print ('error for hamming distance:', err_hamming)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of error for hamming distance: 1463\n",
            "error for hamming distance: 0.01463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5EOuNQlaMrXB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save results"
      ]
    },
    {
      "metadata": {
        "id": "F0E3PUfKMv8V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "str = 'num_err_hamming= {}, pe_hamming= {}, N= {}, M= {}, bsc_err= {}, R= {},\\\n",
        "  hidden_layers= {}, cost_func= {}, epochs={}, dropout={} \\n'.format(num_err_hamming, \n",
        "                                            err_hamming, N, M, bsc_err, R, design, loss, epochs, dropout)\n",
        "file_path = base_path + '/' + filename \n",
        "with open(file_path, \"a\") as myfile:\n",
        "    myfile.write(str)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}